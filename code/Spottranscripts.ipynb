{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot detection on 1 FOV so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage import filters, measure, exposure, morphology, io\n",
    "from skimage.measure import regionprops\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import csv\n",
    "import napari\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "out_opt_flow_registered_X10_Y2_c01_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_DAPI.tif\n"
     ]
    }
   ],
   "source": [
    "#To check if I have the right saved names of my data\n",
    "\n",
    "for file_name in os.listdir(r\"C:\\Users\\s369577\\Desktop\\test\"):\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(filename='spot_detection.log', filemode=\"w\", level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "# Had to check if my directory and the names were correct (yes i checked it two times cuz of trust issues)\n",
    "# print(\"Sample files in directory:\")\n",
    "# for f in os.listdir(r\"C:\\Users\\s369577\\Desktop\\test\"):\n",
    "#     print(f)\n",
    "#     if f.startswith(\"out_opt_flow_registered\"):\n",
    "#         break\n",
    "#threshold = 0.5  # Threshold for intensity to determine presence of a base\n",
    "\n",
    "spot_summary = []\n",
    "total_spots_detected = 0  # Initialize spot counter\n",
    "\n",
    "def find_fovs(data_directory):\n",
    "    \"\"\"Scan the data directory to find all unique FOVs.\"\"\"\n",
    "    fovs = set()\n",
    "    for file_name in os.listdir(data_directory):\n",
    "        if \"out_opt_flow_registered\" in file_name:\n",
    "            parts = file_name.split(\"_\")\n",
    "            # Now find the X and Y identifiers explicitly\n",
    "            for i, part in enumerate(parts):\n",
    "                if part.startswith(\"X\") and i + 1 < len(parts) and parts[i+1].startswith(\"Y\"):\n",
    "                    fov = f\"{part}_{parts[i+1]}\"\n",
    "                    fovs.add(fov)\n",
    "                    #print(fov) just checking if fov is correct\n",
    "    return list(fovs)\n",
    "\n",
    "def load_images(fovs, channel_names, rounds, data_directory):\n",
    "    \"\"\"Load images for each FOV, channel, and round.\"\"\"\n",
    "    fov_images = {}\n",
    "    for fov in fovs:\n",
    "        fov_images[fov] = []\n",
    "        for round_idx in range(rounds):\n",
    "            round_images = []\n",
    "            for channel in channel_names:\n",
    "                file_pattern = f\"{data_directory}/out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\"\n",
    "                file_path = glob.glob(file_pattern)\n",
    "                if file_path:\n",
    "                    image = np.array(Image.open(file_path[0]))\n",
    "                    round_images.append(image)\n",
    "                else:\n",
    "                    logging.warning(f\"File not found for {file_pattern}\")\n",
    "                    round_images.append(None)\n",
    "            fov_images[fov].append(round_images)\n",
    "    return fov_images\n",
    "\n",
    "def preprocess_images(images):\n",
    "    \"\"\"Preprocess images (Gaussian blur and normalization).\"\"\"\n",
    "    processed_images = []\n",
    "    for round_images in images:\n",
    "        round_processed_images = []\n",
    "        for image in round_images:\n",
    "            if image is not None:\n",
    "                blurred = filters.gaussian(image, sigma=1)\n",
    "                normalized = exposure.rescale_intensity(blurred, out_range='uint8')\n",
    "                round_processed_images.append(normalized)\n",
    "            else:\n",
    "                round_processed_images.append(None)\n",
    "        processed_images.append(round_processed_images)\n",
    "    return processed_images\n",
    "\n",
    "def detect_spots(image):\n",
    "    \"\"\"Detect spots in an image using Otsu's thresholding.\"\"\"\n",
    "    if image is not None:\n",
    "        threshold_value = filters.threshold_otsu(image)\n",
    "        binary_image = image > threshold_value\n",
    "        labeled_image, num_features = measure.label(binary_image, return_num=True)\n",
    "        #Filter out very small regions (e.g., noise) by area\n",
    "        spots = [s for s in measure.regionprops(labeled_image) if s.area >= 3]\n",
    "        return spots\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def combine_spots(spots_list):\n",
    "    \"\"\"Combine spots from all rounds and channels.\"\"\"\n",
    "    all_spots = []\n",
    "    for round_spots in spots_list:\n",
    "        for channel_spots in round_spots:\n",
    "            all_spots.extend(channel_spots)\n",
    "    return all_spots\n",
    "\n",
    "def visualize_spots(image, spots, output_dir, fov, channel, round_idx = None):\n",
    "    \"\"\"Visualize detected spots on an image and save the result.\"\"\"\n",
    "    if image is not None:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        for spot in spots:\n",
    "            y, x = spot.centroid\n",
    "            plt.plot(x, y, 'ro')\n",
    "        suffix = f\"_round{round_idx+1}\" if round_idx is not None else \"\"\n",
    "        output_path = f\"{output_dir}/{fov}_{channel}{suffix}_spots.png\"\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        logging.info(f\"Saved visualization for {fov}_{channel} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTING THE SPOtS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "data_directory = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\" #data directory\n",
    "output_directory = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\"  #output directory\n",
    "channel_names = ['Atto_425', 'DAPI', 'Alexa_488', 'Alexa_568', 'Alexa_647', 'Atto_490LS']\n",
    "rounds = 4\n",
    "\n",
    "# Initialize CSV and record already processed FOVs\n",
    "csv_path = os.path.join(output_directory, \"spot_summary.csv\")\n",
    "processed_fovs = set()\n",
    "file_exists = os.path.exists(csv_path)\n",
    "if file_exists:\n",
    "    with open(csv_path, mode=\"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            processed_fovs.add(row[\"FOV\"])\n",
    "\n",
    "# Step 1: Identify all FOVs\n",
    "fovs = find_fovs(data_directory)\n",
    "total_fovs = len(fovs)\n",
    "\n",
    "# Step 2: Load images for all FOVs\n",
    "fov_images = load_images(fovs, channel_names, rounds, data_directory)\n",
    "\n",
    "# Step 3: Process each FOV (skip already processed)\n",
    "for idx, (fov, images) in enumerate(fov_images.items(), 1):\n",
    "    if fov in processed_fovs:\n",
    "        print(f\"Skipping already processed FOV: {fov} ({idx}/{total_fovs})\")\n",
    "        continue\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Processing FOV: {fov} ({idx}/{total_fovs})\")\n",
    "    logging.info(f\"Processing FOV: {fov}\")\n",
    "    processed_images = preprocess_images(images)\n",
    "\n",
    "    # Detect spots in each round and channel\n",
    "    unique_coords = set()\n",
    "\n",
    "    for round_images in processed_images:\n",
    "        for image in round_images:\n",
    "            spots = detect_spots(image)\n",
    "            for spot in spots:\n",
    "                y, x = map(int, spot.centroid)\n",
    "                unique_coords.add((y, x)) #store rounded coordinates of spots\n",
    "\n",
    "    total_spots_detected += len(unique_coords)  # Count unique spots\n",
    "\n",
    "    coords_output_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "    os.makedirs(coords_output_dir, exist_ok=True)\n",
    "    coord_path = os.path.join(coords_output_dir, f\"{fov}_coords.pkl\")\n",
    "    with open(coord_path, 'wb') as f:\n",
    "        pickle.dump(list(unique_coords), f)\n",
    "\n",
    "    # Generate summary and spot visualizations per round and channel\n",
    "    spot_summary = []\n",
    "    for round_idx, round_images in enumerate(images):\n",
    "        for channel_idx, image in enumerate(round_images):\n",
    "            if image is not None:\n",
    "                channel = channel_names[channel_idx]\n",
    "                spots = detect_spots(image)\n",
    "                spot_count = len(spots)\n",
    "                if spot_count > 0:\n",
    "                    visualize_spots(image, spots, output_directory, fov, channel, round_idx)\n",
    "                spot_summary.append([fov, round_idx + 1, channel, spot_count])\n",
    "\n",
    "    # Append spot data to CSV\n",
    "    with open(csv_path, mode='a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"FOV\", \"Round\", \"Channel\", \"Spot Count\"])\n",
    "        for row in spot_summary:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Free memory after each FOV\n",
    "    del processed_images\n",
    "    del unique_coords\n",
    "    del spot_summary\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Done: {fov} in {time.time() - start_time:.1f} seconds\\n\")\n",
    "\n",
    "# Finish logging\n",
    "# logging.shutdown()\n",
    "print(f\"Total unique spots detected across all FOVs: {total_spots_detected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(206, 217), (194, 917), (306, 304), (677, 742), (698, 536)]\n",
      "Total spots: 3194\n"
     ]
    }
   ],
   "source": [
    "# FAILSAVE TEST\n",
    "#  Load the first .pkl file manually\n",
    "path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\\X10_Y2_coords.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "    coords = pickle.load(f)\n",
    "\n",
    "print(coords[:5])  # Preview first 5 spot coordinates\n",
    "print(f\"Total spots: {len(coords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barcode decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_directory = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\"\n",
    "spot_coord_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "output_csv_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "summary_csv_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode_summary.csv\"\n",
    "tagl_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\taglist\\taglist.csv\"\n",
    "channel_names = ['Atto_425', 'DAPI', 'Alexa_488', 'Alexa_568', 'Alexa_647', 'Atto_490LS']\n",
    "rounds = 4\n",
    "\n",
    "# Barcode base mapping\n",
    "channel_to_base = {\n",
    "    'Atto_425': 'A',\n",
    "    'Alexa_488': 'C',\n",
    "    'Alexa_568': 'G',\n",
    "    'Alexa_647': 'T',\n",
    "}\n",
    "\n",
    "decoding_channels = list(channel_to_base.keys())\n",
    "\n",
    "def load_and_preprocess_images(fov, rounds, channel_names):\n",
    "    processed = []\n",
    "    for round_idx in range(rounds):\n",
    "        round_processed = []\n",
    "        for channel in channel_names:\n",
    "            pattern = f\"{data_directory}/out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\"\n",
    "            files = glob.glob(pattern)\n",
    "            if files:\n",
    "                with Image.open(files[0]) as img:\n",
    "                    image = np.array(img)\n",
    "                blurred = filters.gaussian(image, sigma=1)\n",
    "                normalized = exposure.rescale_intensity(blurred, out_range='uint8')\n",
    "                round_processed.append(normalized)\n",
    "            else:\n",
    "                round_processed.append(None)\n",
    "        processed.append(round_processed)\n",
    "    return processed\n",
    "\n",
    "# Load barcode reference\n",
    "taglist_df = pd.read_csv(tagl_path)\n",
    "barcode_to_gene = dict(zip(taglist_df['Code'], taglist_df['Name']))\n",
    "gene_counter = Counter()\n",
    "\n",
    "# Start decoding\n",
    "fovs = find_fovs(data_directory)\n",
    "with open(output_csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"FOV\", \"Y\", \"X\", \"Barcode\", \"Gene\"])\n",
    "\n",
    "    for fov in fovs:\n",
    "        processed_images = load_and_preprocess_images(fov, rounds, channel_names)\n",
    "\n",
    "        # Load saved DAPI-based spot coordinates from pickle\n",
    "        coord_path = os.path.join(spot_coord_dir, f\"{fov}_coords.pkl\")\n",
    "        if not os.path.exists(coord_path):\n",
    "            continue\n",
    "\n",
    "        with open(coord_path, 'rb') as f:\n",
    "            coordinates = pickle.load(f)\n",
    "\n",
    "        for (y, x) in coordinates:\n",
    "            base_sequence = []\n",
    "\n",
    "            intensity_threshold = 0.3  # Adjust this threshold as needed\n",
    "\n",
    "            for round_idx in range(rounds):\n",
    "                max_intensity = -np.inf\n",
    "                best_base = None\n",
    "                for channel_idx, channel in enumerate(channel_names):\n",
    "                    if channel not in decoding_channels:\n",
    "                        continue\n",
    "                    image = processed_images[round_idx][channel_idx]\n",
    "                    if image is None or y >= image.shape[0] or x >= image.shape[1]:\n",
    "                        continue\n",
    "                    intensity = image[y, x]\n",
    "                    if intensity > max_intensity and intensity > intensity_threshold:\n",
    "                        max_intensity = intensity\n",
    "                        best_base = channel_to_base[channel]\n",
    "                base_sequence.append(best_base)\n",
    "\n",
    "            if None in base_sequence:\n",
    "                continue\n",
    "\n",
    "            barcode = ''.join(base_sequence)\n",
    "            gene = barcode_to_gene.get(barcode, \"invalid\")\n",
    "            gene_counter[gene] += 1\n",
    "            writer.writerow([fov, y, x, barcode, gene])\n",
    "\n",
    "# Write gene summary\n",
    "with open(summary_csv_path, 'w', newline='') as summary_file:\n",
    "    writer = csv.writer(summary_file)\n",
    "    writer.writerow(['Gene', 'Count'])\n",
    "    for gene, count in gene_counter.most_common():\n",
    "        writer.writerow([gene, count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved FOV-Gene summary to: C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode_summary.csv\n"
     ]
    }
   ],
   "source": [
    "barcode_csv = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "output_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode_summary.csv\"\n",
    "\n",
    "df = pd.read_csv(barcode_csv)\n",
    "\n",
    "df_filtered = df[df['Gene'] != 'invalid']\n",
    "\n",
    "summary = df_filtered.groupby([\"FOV\", \"Gene\"]).size().reset_index(name='Count')\n",
    "\n",
    "summary.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\" Saved FOV-Gene summary to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "fov = \"X10_Y2\"  # Change to desired FOV\n",
    "data_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\"\n",
    "coords_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "barcode_csv = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "channels = ['Atto_425', 'Alexa_488', 'Alexa_568', 'Alexa_647']\n",
    "channel_colors = {\n",
    "    'Atto_425': 'magenta',\n",
    "    'Alexa_488': 'yellow',\n",
    "    'Alexa_568': 'red',\n",
    "    'Alexa_647': 'green',\n",
    "}\n",
    "\n",
    "# Load all 4 rounds for each channel and stack them\n",
    "layers = []\n",
    "for channel in channels:\n",
    "    for round_idx in range(4):  # 0-based index for 4 rounds\n",
    "        pattern = os.path.join(data_dir, f\"out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\")\n",
    "        if os.path.exists(pattern):\n",
    "            image = np.array(Image.open(pattern))\n",
    "            name = f\"{channel}_R{round_idx+1}\"\n",
    "            color = channel_colors[channel]\n",
    "            layers.append((image, name, color))\n",
    "        else:\n",
    "            print(f\"Image missing: {pattern}\")\n",
    "\n",
    "# Load decoded coordinates and metadata\n",
    "coords = []\n",
    "barcodes = []\n",
    "genes = []\n",
    "\n",
    "if os.path.exists(barcode_csv):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(barcode_csv)\n",
    "    df_fov = df[df['FOV'] == fov]\n",
    "    coords = df_fov[['Y', 'X']].to_numpy()\n",
    "    barcodes = df_fov['Barcode'].tolist()\n",
    "    genes = df_fov['Gene'].tolist()\n",
    "else:\n",
    "    print(f\" Barcode CSV not found at: {barcode_csv}\")\n",
    "\n",
    "# Start napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add round & channel images\n",
    "for img, name, color in layers:\n",
    "    viewer.add_image(img, name=name, colormap=color, blending='additive')\n",
    "\n",
    "# Add predicted points if available\n",
    "if len(coords) > 0:\n",
    "    points_layer = viewer.add_points(\n",
    "        coords,\n",
    "        size=5,\n",
    "        face_color='white',\n",
    "        name='decoded_spots',\n",
    "        properties={'barcode': barcodes, 'gene': genes}\n",
    "    )\n",
    "    # Set edge_color separately\n",
    "    points_layer.edge_color = 'black'\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ALL FOVS\n",
    "(DOch nicht gemacht da sorgen um den Rechner hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Configuration\n",
    "# data_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\"\n",
    "# coords_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "# barcode_csv = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "# channels = ['Atto_425', 'Alexa_488', 'Alexa_568', 'Alexa_647']\n",
    "# channel_colors = {\n",
    "#     'Atto_425': 'magenta',\n",
    "#     'Alexa_488': 'yellow',\n",
    "#     'Alexa_568': 'red',\n",
    "#     'Alexa_647': 'green',\n",
    "# }\n",
    "\n",
    "# # Load FOV list\n",
    "# def find_fovs(directory):\n",
    "#     fovs = set()\n",
    "#     for name in os.listdir(directory):\n",
    "#         if \"out_opt_flow_registered\" in name:\n",
    "#             parts = name.split(\"_\")\n",
    "#             for i, part in enumerate(parts):\n",
    "#                 if part.startswith(\"X\") and i + 1 < len(parts) and parts[i + 1].startswith(\"Y\"):\n",
    "#                     fovs.add(f\"{part}_{parts[i + 1]}\")\n",
    "#     return sorted(fovs)\n",
    "\n",
    "# fovs = find_fovs(data_dir)\n",
    "# df = pd.read_csv(barcode_csv)\n",
    "\n",
    "# # Loop through each FOV\n",
    "# for fov in fovs:\n",
    "#     viewer = napari.Viewer()\n",
    "#     layers = []\n",
    "\n",
    "#     # Load images\n",
    "#     for channel in channels:\n",
    "#         for round_idx in range(4):\n",
    "#             path = os.path.join(data_dir, f\"out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\")\n",
    "#             if os.path.exists(path):\n",
    "#                 img = np.array(Image.open(path))\n",
    "#                 name = f\"{channel}_R{round_idx+1}\"\n",
    "#                 color = channel_colors[channel]\n",
    "#                 viewer.add_image(img, name=name, colormap=color, blending='additive')\n",
    "#             else:\n",
    "#                 print(f\"Missing: {path}\")\n",
    "\n",
    "#     # Load decoded spots for this FOV\n",
    "#     df_fov = df[df[\"FOV\"] == fov]\n",
    "#     if not df_fov.empty:\n",
    "#         coords = df_fov[['Y', 'X']].to_numpy()\n",
    "#         barcodes = df_fov['Barcode'].tolist()\n",
    "#         genes = df_fov['Gene'].tolist()\n",
    "\n",
    "#         points_layer = viewer.add_points(\n",
    "#             coords,\n",
    "#             size=5,\n",
    "#             face_color='white',\n",
    "#             name='decoded_spots',\n",
    "#             properties={'barcode': barcodes, 'gene': genes}\n",
    "#         )\n",
    "#         points_layer.edge_color = 'black'\n",
    "\n",
    "#     print(f\"Viewing {fov}. Close Napari window to proceed to the next.\")\n",
    "#     napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mousebrain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
