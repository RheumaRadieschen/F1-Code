{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot detection on 1 FOV so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage import filters, measure, exposure, morphology, io\n",
    "from skimage.measure import regionprops\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import csv\n",
    "import napari\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "out_opt_flow_registered_X10_Y2_c01_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c01_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c02_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c03_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y2_c04_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c01_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c02_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c03_DAPI.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Alexa_488.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Alexa_568.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Alexa_647.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Atto_425.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_Atto_490LS.tif\n",
      "out_opt_flow_registered_X10_Y3_c04_DAPI.tif\n"
     ]
    }
   ],
   "source": [
    "#To check if I have the right saved names of my data\n",
    "\n",
    "for file_name in os.listdir(r\"C:\\Users\\s369577\\Desktop\\test\"):\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(filename='spot_detection.log', filemode=\"w\", level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "# Had to check if my directory and the names were correct (yes i checked it two times cuz of trust issues)\n",
    "# print(\"Sample files in directory:\")\n",
    "# for f in os.listdir(r\"C:\\Users\\s369577\\Desktop\\test\"):\n",
    "#     print(f)\n",
    "#     if f.startswith(\"out_opt_flow_registered\"):\n",
    "#         break\n",
    "#threshold = 0.5  # Threshold for intensity to determine presence of a base\n",
    "\n",
    "spot_summary = []\n",
    "total_spots_detected = 0  # Initialize spot counter\n",
    "\n",
    "def find_fovs(data_directory):\n",
    "    \"\"\"Scan the data directory to find all unique FOVs.\"\"\"\n",
    "    fovs = set()\n",
    "    for file_name in os.listdir(data_directory):\n",
    "        if \"out_opt_flow_registered\" in file_name:\n",
    "            parts = file_name.split(\"_\")\n",
    "            # Now find the X and Y identifiers explicitly\n",
    "            for i, part in enumerate(parts):\n",
    "                if part.startswith(\"X\") and i + 1 < len(parts) and parts[i+1].startswith(\"Y\"):\n",
    "                    fov = f\"{part}_{parts[i+1]}\"\n",
    "                    fovs.add(fov)\n",
    "                    #print(fov) just checking if fov is correct\n",
    "    return list(fovs)\n",
    "\n",
    "def load_images(fovs, channel_names, rounds, data_directory):\n",
    "    \"\"\"Load images for each FOV, channel, and round.\"\"\"\n",
    "    fov_images = {}\n",
    "    for fov in fovs:\n",
    "        fov_images[fov] = []\n",
    "        for round_idx in range(rounds):\n",
    "            round_images = []\n",
    "            for channel in channel_names:\n",
    "                file_pattern = f\"{data_directory}/out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\"\n",
    "                file_path = glob.glob(file_pattern)\n",
    "                if file_path:\n",
    "                    image = np.array(Image.open(file_path[0]))\n",
    "                    round_images.append(image)\n",
    "                else:\n",
    "                    logging.warning(f\"File not found for {file_pattern}\")\n",
    "                    round_images.append(None)\n",
    "            fov_images[fov].append(round_images)\n",
    "    return fov_images\n",
    "\n",
    "def preprocess_images(images):\n",
    "    \"\"\"Preprocess images (Gaussian blur and normalization).\"\"\"\n",
    "    processed_images = []\n",
    "    for round_images in images:\n",
    "        round_processed_images = []\n",
    "        for image in round_images:\n",
    "            if image is not None:\n",
    "                blurred = filters.gaussian(image, sigma=1)\n",
    "                normalized = exposure.rescale_intensity(blurred, out_range='uint8')\n",
    "                round_processed_images.append(normalized)\n",
    "            else:\n",
    "                round_processed_images.append(None)\n",
    "        processed_images.append(round_processed_images)\n",
    "    return processed_images\n",
    "\n",
    "def detect_spots(image):\n",
    "    \"\"\"Detect spots in an image using Otsu's thresholding.\"\"\"\n",
    "    if image is not None:\n",
    "        threshold_value = filters.threshold_otsu(image)\n",
    "        binary_image = image > threshold_value\n",
    "        labeled_image, num_features = measure.label(binary_image, return_num=True)\n",
    "        #Filter out very small regions (e.g., noise) by area\n",
    "        spots = [s for s in measure.regionprops(labeled_image) if s.area >= 3]\n",
    "        return spots\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def combine_spots(spots_list):\n",
    "    \"\"\"Combine spots from all rounds and channels.\"\"\"\n",
    "    all_spots = []\n",
    "    for round_spots in spots_list:\n",
    "        for channel_spots in round_spots:\n",
    "            all_spots.extend(channel_spots)\n",
    "    return all_spots\n",
    "\n",
    "def visualize_spots(image, spots, output_dir, fov, channel, round_idx = None):\n",
    "    \"\"\"Visualize detected spots on an image and save the result.\"\"\"\n",
    "    if image is not None:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        for spot in spots:\n",
    "            y, x = spot.centroid\n",
    "            plt.plot(x, y, 'ro')\n",
    "        suffix = f\"_round{round_idx+1}\" if round_idx is not None else \"\"\n",
    "        output_path = f\"{output_dir}/{fov}_{channel}{suffix}_spots.png\"\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        logging.info(f\"Saved visualization for {fov}_{channel} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTING THE SPOtS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è© Skipping already processed FOV: X17_Y0 (1/190)\n",
      "‚è© Skipping already processed FOV: X12_Y7 (2/190)\n",
      "‚è© Skipping already processed FOV: X16_Y0 (3/190)\n",
      "‚è© Skipping already processed FOV: X19_Y11 (4/190)\n",
      "üîÑ Processing FOV: X21_Y4 (5/190)\n",
      "‚úÖ Done: X21_Y4 in 18.6 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X14_Y1 (6/190)\n",
      "üîÑ Processing FOV: X19_Y14 (7/190)\n",
      "‚úÖ Done: X19_Y14 in 7.2 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X11_Y1 (8/190)\n",
      "‚è© Skipping already processed FOV: X13_Y15 (9/190)\n",
      "‚è© Skipping already processed FOV: X10_Y6 (10/190)\n",
      "‚è© Skipping already processed FOV: X16_Y15 (11/190)\n",
      "üîÑ Processing FOV: X20_Y5 (12/190)\n",
      "‚úÖ Done: X20_Y5 in 17.0 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X18_Y3 (13/190)\n",
      "üîÑ Processing FOV: X16_Y3 (14/190)\n",
      "‚úÖ Done: X16_Y3 in 14.3 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X11_Y3 (15/190)\n",
      "‚è© Skipping already processed FOV: X19_Y2 (16/190)\n",
      "üîÑ Processing FOV: X17_Y5 (17/190)\n",
      "‚úÖ Done: X17_Y5 in 17.3 seconds\n",
      "\n",
      "üîÑ Processing FOV: X14_Y5 (18/190)\n",
      "‚úÖ Done: X14_Y5 in 20.9 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X17_Y4 (19/190)\n",
      "‚è© Skipping already processed FOV: X18_Y7 (20/190)\n",
      "‚è© Skipping already processed FOV: X14_Y11 (21/190)\n",
      "‚è© Skipping already processed FOV: X20_Y13 (22/190)\n",
      "‚è© Skipping already processed FOV: X12_Y10 (23/190)\n",
      "‚è© Skipping already processed FOV: X15_Y15 (24/190)\n",
      "üîÑ Processing FOV: X23_Y6 (25/190)\n",
      "‚úÖ Done: X23_Y6 in 9.4 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X20_Y10 (26/190)\n",
      "‚è© Skipping already processed FOV: X17_Y15 (27/190)\n",
      "‚è© Skipping already processed FOV: X22_Y10 (28/190)\n",
      "üîÑ Processing FOV: X18_Y2 (29/190)\n",
      "‚úÖ Done: X18_Y2 in 17.5 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X15_Y8 (30/190)\n",
      "‚è© Skipping already processed FOV: X20_Y6 (31/190)\n",
      "üîÑ Processing FOV: X15_Y4 (32/190)\n",
      "‚úÖ Done: X15_Y4 in 19.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X23_Y5 (33/190)\n",
      "‚è© Skipping already processed FOV: X17_Y3 (34/190)\n",
      "üîÑ Processing FOV: X21_Y6 (35/190)\n",
      "‚úÖ Done: X21_Y6 in 19.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X14_Y15 (36/190)\n",
      "‚è© Skipping already processed FOV: X17_Y7 (37/190)\n",
      "üîÑ Processing FOV: X14_Y3 (38/190)\n",
      "‚úÖ Done: X14_Y3 in 18.8 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X18_Y6 (39/190)\n",
      "üîÑ Processing FOV: X10_Y11 (40/190)\n",
      "‚úÖ Done: X10_Y11 in 22.3 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X16_Y4 (41/190)\n",
      "‚è© Skipping already processed FOV: X19_Y4 (42/190)\n",
      "‚è© Skipping already processed FOV: X21_Y10 (43/190)\n",
      "‚è© Skipping already processed FOV: X12_Y14 (44/190)\n",
      "üîÑ Processing FOV: X20_Y4 (45/190)\n",
      "‚úÖ Done: X20_Y4 in 20.1 seconds\n",
      "\n",
      "üîÑ Processing FOV: X12_Y1 (46/190)\n",
      "‚úÖ Done: X12_Y1 in 21.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X16_Y10 (47/190)\n",
      "üîÑ Processing FOV: X17_Y10 (48/190)\n",
      "‚úÖ Done: X17_Y10 in 25.3 seconds\n",
      "\n",
      "üîÑ Processing FOV: X11_Y5 (49/190)\n",
      "‚úÖ Done: X11_Y5 in 20.2 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X17_Y14 (50/190)\n",
      "‚è© Skipping already processed FOV: X10_Y13 (51/190)\n",
      "üîÑ Processing FOV: X13_Y1 (52/190)\n",
      "‚úÖ Done: X13_Y1 in 22.6 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X19_Y9 (53/190)\n",
      "‚è© Skipping already processed FOV: X10_Y12 (54/190)\n",
      "üîÑ Processing FOV: X21_Y5 (55/190)\n",
      "‚úÖ Done: X21_Y5 in 21.2 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X12_Y2 (56/190)\n",
      "‚è© Skipping already processed FOV: X15_Y3 (57/190)\n",
      "‚è© Skipping already processed FOV: X14_Y16 (58/190)\n",
      "‚è© Skipping already processed FOV: X13_Y14 (59/190)\n",
      "üîÑ Processing FOV: X11_Y6 (60/190)\n",
      "‚úÖ Done: X11_Y6 in 22.9 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X18_Y13 (61/190)\n",
      "üîÑ Processing FOV: X18_Y11 (62/190)\n",
      "‚úÖ Done: X18_Y11 in 24.6 seconds\n",
      "\n",
      "üîÑ Processing FOV: X14_Y6 (63/190)\n",
      "‚úÖ Done: X14_Y6 in 25.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X11_Y8 (64/190)\n",
      "‚è© Skipping already processed FOV: X21_Y11 (65/190)\n",
      "‚è© Skipping already processed FOV: X12_Y0 (66/190)\n",
      "üîÑ Processing FOV: X17_Y2 (67/190)\n",
      "‚úÖ Done: X17_Y2 in 22.5 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X21_Y12 (68/190)\n",
      "üîÑ Processing FOV: X14_Y9 (69/190)\n",
      "‚úÖ Done: X14_Y9 in 26.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X20_Y11 (70/190)\n",
      "‚è© Skipping already processed FOV: X10_Y15 (71/190)\n",
      "üîÑ Processing FOV: X13_Y7 (72/190)\n",
      "‚úÖ Done: X13_Y7 in 26.4 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X10_Y10 (73/190)\n",
      "‚è© Skipping already processed FOV: X11_Y10 (74/190)\n",
      "‚è© Skipping already processed FOV: X12_Y4 (75/190)\n",
      "üîÑ Processing FOV: X16_Y7 (76/190)\n",
      "‚úÖ Done: X16_Y7 in 27.6 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X18_Y5 (77/190)\n",
      "‚è© Skipping already processed FOV: X13_Y3 (78/190)\n",
      "‚è© Skipping already processed FOV: X13_Y8 (79/190)\n",
      "‚è© Skipping already processed FOV: X18_Y12 (80/190)\n",
      "üîÑ Processing FOV: X11_Y2 (81/190)\n",
      "‚úÖ Done: X11_Y2 in 25.5 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X19_Y13 (82/190)\n",
      "‚è© Skipping already processed FOV: X15_Y5 (83/190)\n",
      "‚è© Skipping already processed FOV: X16_Y11 (84/190)\n",
      "‚è© Skipping already processed FOV: X17_Y9 (85/190)\n",
      "‚è© Skipping already processed FOV: X18_Y14 (86/190)\n",
      "‚è© Skipping already processed FOV: X15_Y13 (87/190)\n",
      "‚è© Skipping already processed FOV: X13_Y11 (88/190)\n",
      "‚è© Skipping already processed FOV: X23_Y7 (89/190)\n",
      "‚è© Skipping already processed FOV: X19_Y5 (90/190)\n",
      "‚è© Skipping already processed FOV: X16_Y1 (91/190)\n",
      "‚è© Skipping already processed FOV: X20_Y2 (92/190)\n",
      "‚è© Skipping already processed FOV: X17_Y13 (93/190)\n",
      "‚è© Skipping already processed FOV: X16_Y12 (94/190)\n",
      "‚è© Skipping already processed FOV: X20_Y3 (95/190)\n",
      "üîÑ Processing FOV: X15_Y0 (96/190)\n",
      "‚úÖ Done: X15_Y0 in 19.8 seconds\n",
      "\n",
      "üîÑ Processing FOV: X20_Y12 (97/190)\n",
      "‚úÖ Done: X20_Y12 in 26.0 seconds\n",
      "\n",
      "üîÑ Processing FOV: X13_Y13 (98/190)\n",
      "‚úÖ Done: X13_Y13 in 28.5 seconds\n",
      "\n",
      "üîÑ Processing FOV: X23_Y4 (99/190)\n",
      "‚úÖ Done: X23_Y4 in 29.8 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X10_Y2 (100/190)\n",
      "‚è© Skipping already processed FOV: X11_Y9 (101/190)\n",
      "‚è© Skipping already processed FOV: X14_Y7 (102/190)\n",
      "‚è© Skipping already processed FOV: X16_Y5 (103/190)\n",
      "‚è© Skipping already processed FOV: X20_Y7 (104/190)\n",
      "‚è© Skipping already processed FOV: X17_Y11 (105/190)\n",
      "‚è© Skipping already processed FOV: X12_Y12 (106/190)\n",
      "üîÑ Processing FOV: X15_Y12 (107/190)\n",
      "‚úÖ Done: X15_Y12 in 31.3 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X14_Y10 (108/190)\n",
      "‚è© Skipping already processed FOV: X19_Y1 (109/190)\n",
      "üîÑ Processing FOV: X12_Y9 (110/190)\n",
      "‚úÖ Done: X12_Y9 in 30.2 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X12_Y11 (111/190)\n",
      "‚è© Skipping already processed FOV: X10_Y8 (112/190)\n",
      "üîÑ Processing FOV: X12_Y5 (113/190)\n",
      "‚úÖ Done: X12_Y5 in 34.4 seconds\n",
      "\n",
      "üîÑ Processing FOV: X12_Y13 (114/190)\n",
      "‚úÖ Done: X12_Y13 in 29.8 seconds\n",
      "\n",
      "üîÑ Processing FOV: X15_Y9 (115/190)\n",
      "‚úÖ Done: X15_Y9 in 32.5 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X10_Y4 (116/190)\n",
      "üîÑ Processing FOV: X10_Y14 (117/190)\n",
      "‚úÖ Done: X10_Y14 in 32.7 seconds\n",
      "\n",
      "üîÑ Processing FOV: X14_Y12 (118/190)\n",
      "‚úÖ Done: X14_Y12 in 35.3 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X15_Y7 (119/190)\n",
      "‚è© Skipping already processed FOV: X16_Y2 (120/190)\n",
      "‚è© Skipping already processed FOV: X20_Y9 (121/190)\n",
      "‚è© Skipping already processed FOV: X13_Y6 (122/190)\n",
      "‚è© Skipping already processed FOV: X22_Y6 (123/190)\n",
      "üîÑ Processing FOV: X11_Y12 (124/190)\n",
      "‚úÖ Done: X11_Y12 in 33.6 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X21_Y3 (125/190)\n",
      "‚è© Skipping already processed FOV: X19_Y10 (126/190)\n",
      "‚è© Skipping already processed FOV: X12_Y15 (127/190)\n",
      "üîÑ Processing FOV: X15_Y1 (128/190)\n",
      "‚úÖ Done: X15_Y1 in 31.7 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X13_Y9 (129/190)\n",
      "‚è© Skipping already processed FOV: X18_Y9 (130/190)\n",
      "‚è© Skipping already processed FOV: X15_Y6 (131/190)\n",
      "üîÑ Processing FOV: X17_Y12 (132/190)\n",
      "‚úÖ Done: X17_Y12 in 32.4 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X16_Y13 (133/190)\n",
      "üîÑ Processing FOV: X21_Y9 (134/190)\n",
      "‚úÖ Done: X21_Y9 in 32.4 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X16_Y9 (135/190)\n",
      "üîÑ Processing FOV: X13_Y2 (136/190)\n",
      "‚úÖ Done: X13_Y2 in 33.9 seconds\n",
      "\n",
      "üîÑ Processing FOV: X19_Y6 (137/190)\n",
      "‚úÖ Done: X19_Y6 in 34.2 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X21_Y2 (138/190)\n",
      "‚è© Skipping already processed FOV: X13_Y4 (139/190)\n",
      "‚è© Skipping already processed FOV: X22_Y4 (140/190)\n",
      "‚è© Skipping already processed FOV: X12_Y3 (141/190)\n",
      "‚è© Skipping already processed FOV: X14_Y2 (142/190)\n",
      "üîÑ Processing FOV: X17_Y6 (143/190)\n",
      "‚úÖ Done: X17_Y6 in 35.2 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X13_Y12 (144/190)\n",
      "‚è© Skipping already processed FOV: X10_Y9 (145/190)\n",
      "üîÑ Processing FOV: X22_Y7 (146/190)\n",
      "‚úÖ Done: X22_Y7 in 33.9 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X15_Y11 (147/190)\n",
      "‚è© Skipping already processed FOV: X18_Y10 (148/190)\n",
      "‚è© Skipping already processed FOV: X13_Y5 (149/190)\n",
      "‚è© Skipping already processed FOV: X11_Y15 (150/190)\n",
      "‚è© Skipping already processed FOV: X13_Y10 (151/190)\n",
      "‚è© Skipping already processed FOV: X10_Y3 (152/190)\n",
      "‚è© Skipping already processed FOV: X15_Y2 (153/190)\n",
      "‚è© Skipping already processed FOV: X11_Y7 (154/190)\n",
      "üîÑ Processing FOV: X18_Y4 (155/190)\n",
      "‚úÖ Done: X18_Y4 in 34.7 seconds\n",
      "\n",
      "üîÑ Processing FOV: X14_Y8 (156/190)\n",
      "‚úÖ Done: X14_Y8 in 38.0 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X14_Y4 (157/190)\n",
      "‚è© Skipping already processed FOV: X17_Y8 (158/190)\n",
      "‚è© Skipping already processed FOV: X19_Y7 (159/190)\n",
      "üîÑ Processing FOV: X14_Y0 (160/190)\n",
      "‚úÖ Done: X14_Y0 in 28.7 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X15_Y10 (161/190)\n",
      "‚è© Skipping already processed FOV: X22_Y9 (162/190)\n",
      "‚è© Skipping already processed FOV: X22_Y5 (163/190)\n",
      "‚è© Skipping already processed FOV: X11_Y14 (164/190)\n",
      "‚è© Skipping already processed FOV: X19_Y8 (165/190)\n",
      "üîÑ Processing FOV: X22_Y3 (166/190)\n",
      "‚úÖ Done: X22_Y3 in 27.3 seconds\n",
      "\n",
      "üîÑ Processing FOV: X10_Y7 (167/190)\n",
      "‚úÖ Done: X10_Y7 in 39.6 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X23_Y8 (168/190)\n",
      "‚è© Skipping already processed FOV: X16_Y6 (169/190)\n",
      "‚è© Skipping already processed FOV: X18_Y1 (170/190)\n",
      "üîÑ Processing FOV: X16_Y8 (171/190)\n",
      "‚úÖ Done: X16_Y8 in 38.6 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X14_Y14 (172/190)\n",
      "‚è© Skipping already processed FOV: X15_Y14 (173/190)\n",
      "‚è© Skipping already processed FOV: X21_Y8 (174/190)\n",
      "‚è© Skipping already processed FOV: X11_Y11 (175/190)\n",
      "‚è© Skipping already processed FOV: X14_Y13 (176/190)\n",
      "üîÑ Processing FOV: X22_Y8 (177/190)\n",
      "‚úÖ Done: X22_Y8 in 35.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X20_Y8 (178/190)\n",
      "üîÑ Processing FOV: X11_Y4 (179/190)\n",
      "‚úÖ Done: X11_Y4 in 36.5 seconds\n",
      "\n",
      "üîÑ Processing FOV: X21_Y7 (180/190)\n",
      "‚úÖ Done: X21_Y7 in 35.0 seconds\n",
      "\n",
      "üîÑ Processing FOV: X12_Y6 (181/190)\n",
      "‚úÖ Done: X12_Y6 in 41.8 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X13_Y0 (182/190)\n",
      "‚è© Skipping already processed FOV: X10_Y5 (183/190)\n",
      "‚è© Skipping already processed FOV: X16_Y14 (184/190)\n",
      "‚è© Skipping already processed FOV: X18_Y8 (185/190)\n",
      "üîÑ Processing FOV: X19_Y12 (186/190)\n",
      "‚úÖ Done: X19_Y12 in 42.1 seconds\n",
      "\n",
      "‚è© Skipping already processed FOV: X17_Y1 (187/190)\n",
      "‚è© Skipping already processed FOV: X19_Y3 (188/190)\n",
      "‚è© Skipping already processed FOV: X12_Y8 (189/190)\n",
      "‚è© Skipping already processed FOV: X11_Y13 (190/190)\n",
      "Total unique spots detected across all FOVs: 435335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "data_directory = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\" #data directory\n",
    "output_directory = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\"  #output directory\n",
    "channel_names = ['Atto_425', 'DAPI', 'Alexa_488', 'Alexa_568', 'Alexa_647', 'Atto_490LS']\n",
    "rounds = 4\n",
    "\n",
    "# Initialize CSV and record already processed FOVs\n",
    "csv_path = os.path.join(output_directory, \"spot_summary.csv\")\n",
    "processed_fovs = set()\n",
    "file_exists = os.path.exists(csv_path)\n",
    "if file_exists:\n",
    "    with open(csv_path, mode=\"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            processed_fovs.add(row[\"FOV\"])\n",
    "\n",
    "# Step 1: Identify all FOVs\n",
    "fovs = find_fovs(data_directory)\n",
    "total_fovs = len(fovs)\n",
    "\n",
    "# Step 2: Load images for all FOVs\n",
    "fov_images = load_images(fovs, channel_names, rounds, data_directory)\n",
    "\n",
    "# Step 3: Process each FOV (skip already processed)\n",
    "for idx, (fov, images) in enumerate(fov_images.items(), 1):\n",
    "    if fov in processed_fovs:\n",
    "        print(f\"Skipping already processed FOV: {fov} ({idx}/{total_fovs})\")\n",
    "        continue\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Processing FOV: {fov} ({idx}/{total_fovs})\")\n",
    "    logging.info(f\"Processing FOV: {fov}\")\n",
    "    processed_images = preprocess_images(images)\n",
    "\n",
    "    # Detect spots in each round and channel\n",
    "    unique_coords = set()\n",
    "\n",
    "    for round_images in processed_images:\n",
    "        for image in round_images:\n",
    "            spots = detect_spots(image)\n",
    "            for spot in spots:\n",
    "                y, x = map(int, spot.centroid)\n",
    "                unique_coords.add((y, x)) #store rounded coordinates of spots\n",
    "\n",
    "    total_spots_detected += len(unique_coords)  # Count unique spots\n",
    "\n",
    "    coords_output_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "    os.makedirs(coords_output_dir, exist_ok=True)\n",
    "    coord_path = os.path.join(coords_output_dir, f\"{fov}_coords.pkl\")\n",
    "    with open(coord_path, 'wb') as f:\n",
    "        pickle.dump(list(unique_coords), f)\n",
    "\n",
    "    # Generate summary and spot visualizations per round and channel\n",
    "    spot_summary = []\n",
    "    for round_idx, round_images in enumerate(images):\n",
    "        for channel_idx, image in enumerate(round_images):\n",
    "            if image is not None:\n",
    "                channel = channel_names[channel_idx]\n",
    "                spots = detect_spots(image)\n",
    "                spot_count = len(spots)\n",
    "                if spot_count > 0:\n",
    "                    visualize_spots(image, spots, output_directory, fov, channel, round_idx)\n",
    "                spot_summary.append([fov, round_idx + 1, channel, spot_count])\n",
    "\n",
    "    # Append spot data to CSV\n",
    "    with open(csv_path, mode='a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"FOV\", \"Round\", \"Channel\", \"Spot Count\"])\n",
    "        for row in spot_summary:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Free memory after each FOV\n",
    "    del processed_images\n",
    "    del unique_coords\n",
    "    del spot_summary\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Done: {fov} in {time.time() - start_time:.1f} seconds\\n\")\n",
    "\n",
    "# Finish logging\n",
    "logging.shutdown()\n",
    "print(f\"Total unique spots detected across all FOVs: {total_spots_detected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(206, 217), (194, 917), (306, 304), (677, 742), (698, 536)]\n",
      "Total spots: 3194\n"
     ]
    }
   ],
   "source": [
    "# FAILSAVE TEST\n",
    "#  Load the first .pkl file manually\n",
    "path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\\X10_Y2_coords.pkl\"\n",
    "with open(path, \"rb\") as f:\n",
    "    coords = pickle.load(f)\n",
    "\n",
    "print(coords[:5])  # Preview first 5 spot coordinates\n",
    "print(f\"Total spots: {len(coords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barcode decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_directory = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\"\n",
    "spot_coord_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "output_csv_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "summary_csv_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode_summary.csv\"\n",
    "tagl_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\taglist\\taglist.csv\"\n",
    "channel_names = ['Atto_425', 'DAPI', 'Alexa_488', 'Alexa_568', 'Alexa_647', 'Atto_490LS']\n",
    "rounds = 4\n",
    "\n",
    "# Barcode base mapping\n",
    "channel_to_base = {\n",
    "    'Atto_425': 'A',\n",
    "    'Alexa_488': 'C',\n",
    "    'Alexa_568': 'G',\n",
    "    'Alexa_647': 'T',\n",
    "}\n",
    "\n",
    "decoding_channels = list(channel_to_base.keys())\n",
    "\n",
    "def load_and_preprocess_images(fov, rounds, channel_names):\n",
    "    processed = []\n",
    "    for round_idx in range(rounds):\n",
    "        round_processed = []\n",
    "        for channel in channel_names:\n",
    "            pattern = f\"{data_directory}/out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\"\n",
    "            files = glob.glob(pattern)\n",
    "            if files:\n",
    "                with Image.open(files[0]) as img:\n",
    "                    image = np.array(img)\n",
    "                blurred = filters.gaussian(image, sigma=1)\n",
    "                normalized = exposure.rescale_intensity(blurred, out_range='uint8')\n",
    "                round_processed.append(normalized)\n",
    "            else:\n",
    "                round_processed.append(None)\n",
    "        processed.append(round_processed)\n",
    "    return processed\n",
    "\n",
    "# Load barcode reference\n",
    "taglist_df = pd.read_csv(tagl_path)\n",
    "barcode_to_gene = dict(zip(taglist_df['Code'], taglist_df['Name']))\n",
    "gene_counter = Counter()\n",
    "\n",
    "# Start decoding\n",
    "fovs = find_fovs(data_directory)\n",
    "with open(output_csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"FOV\", \"Y\", \"X\", \"Barcode\", \"Gene\"])\n",
    "\n",
    "    for fov in fovs:\n",
    "        processed_images = load_and_preprocess_images(fov, rounds, channel_names)\n",
    "\n",
    "        # Load saved DAPI-based spot coordinates from pickle\n",
    "        coord_path = os.path.join(spot_coord_dir, f\"{fov}_coords.pkl\")\n",
    "        if not os.path.exists(coord_path):\n",
    "            continue\n",
    "\n",
    "        with open(coord_path, 'rb') as f:\n",
    "            coordinates = pickle.load(f)\n",
    "\n",
    "        for (y, x) in coordinates:\n",
    "            base_sequence = []\n",
    "\n",
    "            intensity_threshold = 0.3  # Adjust this threshold as needed\n",
    "\n",
    "            for round_idx in range(rounds):\n",
    "                max_intensity = -np.inf\n",
    "                best_base = None\n",
    "                for channel_idx, channel in enumerate(channel_names):\n",
    "                    if channel not in decoding_channels:\n",
    "                        continue\n",
    "                    image = processed_images[round_idx][channel_idx]\n",
    "                    if image is None or y >= image.shape[0] or x >= image.shape[1]:\n",
    "                        continue\n",
    "                    intensity = image[y, x]\n",
    "                    if intensity > max_intensity and intensity > intensity_threshold:\n",
    "                        max_intensity = intensity\n",
    "                        best_base = channel_to_base[channel]\n",
    "                base_sequence.append(best_base)\n",
    "\n",
    "            if None in base_sequence:\n",
    "                continue\n",
    "\n",
    "            barcode = ''.join(base_sequence)\n",
    "            gene = barcode_to_gene.get(barcode, \"invalid\")\n",
    "            gene_counter[gene] += 1\n",
    "            writer.writerow([fov, y, x, barcode, gene])\n",
    "\n",
    "# Write gene summary\n",
    "with open(summary_csv_path, 'w', newline='') as summary_file:\n",
    "    writer = csv.writer(summary_file)\n",
    "    writer.writerow(['Gene', 'Count'])\n",
    "    for gene, count in gene_counter.most_common():\n",
    "        writer.writerow([gene, count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved FOV-Gene summary to: C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode_summary.csv\n"
     ]
    }
   ],
   "source": [
    "barcode_csv = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "output_path = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode_summary.csv\"\n",
    "\n",
    "df = pd.read_csv(barcode_csv)\n",
    "\n",
    "df_filtered = df[df['Gene'] != 'invalid']\n",
    "\n",
    "summary = df_filtered.groupby([\"FOV\", \"Gene\"]).size().reset_index(name='Count')\n",
    "\n",
    "summary.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\" Saved FOV-Gene summary to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "fov = \"X10_Y2\"  # Change to desired FOV\n",
    "data_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\"\n",
    "coords_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "barcode_csv = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "channels = ['Atto_425', 'Alexa_488', 'Alexa_568', 'Alexa_647']\n",
    "channel_colors = {\n",
    "    'Atto_425': 'magenta',\n",
    "    'Alexa_488': 'yellow',\n",
    "    'Alexa_568': 'red',\n",
    "    'Alexa_647': 'green',\n",
    "}\n",
    "\n",
    "# Load all 4 rounds for each channel and stack them\n",
    "layers = []\n",
    "for channel in channels:\n",
    "    for round_idx in range(4):  # 0-based index for 4 rounds\n",
    "        pattern = os.path.join(data_dir, f\"out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\")\n",
    "        if os.path.exists(pattern):\n",
    "            image = np.array(Image.open(pattern))\n",
    "            name = f\"{channel}_R{round_idx+1}\"\n",
    "            color = channel_colors[channel]\n",
    "            layers.append((image, name, color))\n",
    "        else:\n",
    "            print(f\"Image missing: {pattern}\")\n",
    "\n",
    "# Load decoded coordinates and metadata\n",
    "coords = []\n",
    "barcodes = []\n",
    "genes = []\n",
    "\n",
    "if os.path.exists(barcode_csv):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(barcode_csv)\n",
    "    df_fov = df[df['FOV'] == fov]\n",
    "    coords = df_fov[['Y', 'X']].to_numpy()\n",
    "    barcodes = df_fov['Barcode'].tolist()\n",
    "    genes = df_fov['Gene'].tolist()\n",
    "else:\n",
    "    print(f\" Barcode CSV not found at: {barcode_csv}\")\n",
    "\n",
    "# Start napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add round & channel images\n",
    "for img, name, color in layers:\n",
    "    viewer.add_image(img, name=name, colormap=color, blending='additive')\n",
    "\n",
    "# Add predicted points if available\n",
    "if len(coords) > 0:\n",
    "    points_layer = viewer.add_points(\n",
    "        coords,\n",
    "        size=5,\n",
    "        face_color='white',\n",
    "        name='decoded_spots',\n",
    "        properties={'barcode': barcodes, 'gene': genes}\n",
    "    )\n",
    "    # Set edge_color separately\n",
    "    points_layer.edge_color = 'black'\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ALL FOVS\n",
    "(DOch nicht gemacht da sorgen um den Rechner hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Configuration\n",
    "# data_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\data\\selected-tiles\\selected-tiles\"\n",
    "# coords_dir = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\spot_detected\\coords\"\n",
    "# barcode_csv = r\"C:\\Users\\s369577\\Desktop\\F1 CCTB\\results\\Barcode\\barcode.csv\"\n",
    "# channels = ['Atto_425', 'Alexa_488', 'Alexa_568', 'Alexa_647']\n",
    "# channel_colors = {\n",
    "#     'Atto_425': 'magenta',\n",
    "#     'Alexa_488': 'yellow',\n",
    "#     'Alexa_568': 'red',\n",
    "#     'Alexa_647': 'green',\n",
    "# }\n",
    "\n",
    "# # Load FOV list\n",
    "# def find_fovs(directory):\n",
    "#     fovs = set()\n",
    "#     for name in os.listdir(directory):\n",
    "#         if \"out_opt_flow_registered\" in name:\n",
    "#             parts = name.split(\"_\")\n",
    "#             for i, part in enumerate(parts):\n",
    "#                 if part.startswith(\"X\") and i + 1 < len(parts) and parts[i + 1].startswith(\"Y\"):\n",
    "#                     fovs.add(f\"{part}_{parts[i + 1]}\")\n",
    "#     return sorted(fovs)\n",
    "\n",
    "# fovs = find_fovs(data_dir)\n",
    "# df = pd.read_csv(barcode_csv)\n",
    "\n",
    "# # Loop through each FOV\n",
    "# for fov in fovs:\n",
    "#     viewer = napari.Viewer()\n",
    "#     layers = []\n",
    "\n",
    "#     # Load images\n",
    "#     for channel in channels:\n",
    "#         for round_idx in range(4):\n",
    "#             path = os.path.join(data_dir, f\"out_opt_flow_registered_{fov}_c{round_idx+1:02d}_{channel}.tif\")\n",
    "#             if os.path.exists(path):\n",
    "#                 img = np.array(Image.open(path))\n",
    "#                 name = f\"{channel}_R{round_idx+1}\"\n",
    "#                 color = channel_colors[channel]\n",
    "#                 viewer.add_image(img, name=name, colormap=color, blending='additive')\n",
    "#             else:\n",
    "#                 print(f\"Missing: {path}\")\n",
    "\n",
    "#     # Load decoded spots for this FOV\n",
    "#     df_fov = df[df[\"FOV\"] == fov]\n",
    "#     if not df_fov.empty:\n",
    "#         coords = df_fov[['Y', 'X']].to_numpy()\n",
    "#         barcodes = df_fov['Barcode'].tolist()\n",
    "#         genes = df_fov['Gene'].tolist()\n",
    "\n",
    "#         points_layer = viewer.add_points(\n",
    "#             coords,\n",
    "#             size=5,\n",
    "#             face_color='white',\n",
    "#             name='decoded_spots',\n",
    "#             properties={'barcode': barcodes, 'gene': genes}\n",
    "#         )\n",
    "#         points_layer.edge_color = 'black'\n",
    "\n",
    "#     print(f\"Viewing {fov}. Close Napari window to proceed to the next.\")\n",
    "#     napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mousebrain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
